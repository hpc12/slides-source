\documentclass[english,compress]{beamer}
\input{settings}

\begin{document}
% {{{ front matter

\title{High-Performance Scientific Computing\\Lecture 4: OpenCL}

\date{MATH-GA 2011 / CSCI-GA 2945 $\cdot$ September 26, 2012}

\frame{\titlepage}

\begin{frame}{Today}
  \tableofcontents[hideallsubsections]
\end{frame}
% }}}
% -----------------------------------------------------------------------------
\begin{frame}{Admin Bits}
  \begin{itemize}[<+->]
    \item HW1 graded before weekend
    \item HW2 due
    \item HW3 out
  \end{itemize}
\end{frame}
% -----------------------------------------------------------------------------
\section{HW2}
% -----------------------------------------------------------------------------
\begin{frame}{HW2 problem 2}
  \begin{center}
  \Huge Demo time
  \end{center}
\end{frame}
% -----------------------------------------------------------------------------
\begin{frame}{OpenMP sync primitives}
  \begin{itemize}[<+->]
    \item Critical section
    \item Locks
    \item Atomics
      \begin{itemize}
        \item Update: \texttt{x++;}
        \item Capture: \texttt{v = x++;}
        \item Structured: {v = x; x |= expr;} (``Test-and-set'')
        \item Compare-and-swap (not in OpenMP)
      \end{itemize}
  \end{itemize}
\end{frame}
% -----------------------------------------------------------------------------
\section{Chips for Throughput}
% -----------------------------------------------------------------------------
% {{{
\input{cpu-chip-real-estate}

\newcommand{\kayvoncredit}{
  \begin{tikzpicture}[overlay]
    \node [xshift=1cm,yshift=0.5cm]
      at (current page.south west)
      [font=\scriptsize,fill=gray!30,anchor=south west,opacity=0.5]
      {Credit: Kayvon Fatahalian (Stanford) };
  \end{tikzpicture}
}
\newcommand{\kayvonframe}[5]{

  \begin{frame}{#1}
    #4
    \begin{center}
    \includegraphics[viewport=#3,clip=true,page=#2,height=0.7\textheight]{kayvon-gpuarch.pdf}
    \end{center}
    \kayvoncredit
    #5
  \end{frame}
}

\kayvonframe{``CPU-style'' Cores}{13}{1in 1in 9in 6.5in }{}{}
\kayvonframe{Slimming down}{14}{1in 1in 9in 6.5in }{}{}
\kayvonframe{More Space: Double the Number of Cores}{15}{2.5in 1in 8.5in 6.5in }{}{}
\kayvonframe{\dots again}{16}{4in 1in 9.5in 6.5in }{}{}
\kayvonframe{\dots and again}{17}{4in 1.35in 9.5in 6.5in }{}{
  \uncover<2>{
    \begin{tikzpicture} [overlay]
      \node [above left=1cm of current page.south east, draw,drop shadow,fill=white,
      text width=0.6\textwidth, inner xsep=0.5cm,inner ysep=0.5cm,thick]
        {
          $\rightarrow$ 16 independent instruction streams

          \medskip
          Reality: instruction streams not actually
          very different/independent
        } ;
    \end{tikzpicture}
  }
}
\begin{frame}{Saving Yet More Space}
  \begin{columns}
    \column{0.5\textwidth}
      \only<1-2>{%
      \includegraphics[viewport=1.8in 3.8in 5.45in 6.25in,clip=true,page=19,width=\textwidth]{kayvon-gpuarch.pdf}\\[-0.5mm]
      \includegraphics[viewport=1.8in 1.35in 5.45in 3.8in,clip=true,page=19,width=\textwidth]{kayvon-gpuarch.pdf}
      }%
      \only<3>{%
      \includegraphics[viewport=1.8in 3.8in 5.45in 6.25in,clip=true,page=20,width=\textwidth]{kayvon-gpuarch.pdf}\\[-0.5mm]
      \includegraphics[viewport=1.8in 1.35in 5.45in 3.8in,clip=true,page=19,width=\textwidth]{kayvon-gpuarch.pdf}
      }%
      \only<4->{%
      \includegraphics[viewport=1.8in 3.8in 5.45in 6.25in,clip=true,page=20,width=\textwidth]{kayvon-gpuarch.pdf}\\[-0.5mm]
      \includegraphics[viewport=1.8in 1.35in 5.45in 3.8in,clip=true,page=20,width=\textwidth]{kayvon-gpuarch.pdf}
      }
    \column{0.5\textwidth}%
      \uncover<2->{%
        \textbf{Idea \#2}

        \medskip
        Amortize cost/complexity of managing an instruction
        stream across many ALUs

        \medskip
        \large \textbf{$\rightarrow$ SIMD}
      }
  \end{columns}
  \kayvoncredit
\end{frame}
\kayvonframe{Gratuitous Amounts of Parallelism!}{24}{5in 1.45in 10in 6.75in }{}{
  \uncover<2->{
    \begin{tikzpicture} [overlay]
      \node [below right=1.75cm of current page.north west, draw,drop shadow,fill=white,
      text width=0.8\textwidth, inner sep=2.5mm,thick]
        {
          Example:

          \medskip
          128 instruction streams in parallel

          16 independent groups of 8 synchronized streams
        } ;
    \end{tikzpicture}
  }
  \uncover<3>{
    \begin{tikzpicture} [overlay]
      \node [above left=1cm of current page.south east, draw,drop shadow,fill=white,
      text width=0.6\textwidth, inner xsep=0.5cm,inner ysep=0.5cm,thick]
        {
          Great if everybody in a group does the same thing.

          \medskip
          But what if not?

          \medskip
          What leads to divergent instruction streams?
        } ;
    \end{tikzpicture}
  }
}
\kayvonframe{Branches}{26}{0.85in 0.9in 10.5in 6.8in }{}{}
\kayvonframe{Branches}{27}{0.85in 0.9in 10.5in 6.8in }{}{}
\kayvonframe{Branches}{28}{0.85in 0.9in 10.5in 6.8in }{}{}
\kayvonframe{Branches}{29}{0.85in 0.9in 10.5in 6.8in }{}{}

\begin{frame}{Recent Processor Architecture}
  \begin{columns}
    \column{0.5\textwidth}
      \begin{itemize}
      \item Commodity chips
      \item ``Infinitely'' many cores
      \item ``Infinite'' vector width
      \item Must hide memory latency\\
        ($\rightarrow$ ILP, SMT)
      \end{itemize}
    \column{0.5\textwidth}
      \begin{itemize}
      \item Compute bandwidth\\
        \hfill $\gg$ Memory bandwidth
      \item Bandwidth only achievable by \emph{homogeneity}
      \end{itemize}
      \vspace*{3.5ex}
  \end{columns}
  \hspace*{-0.25\textwidth}
  \begin{tabular}{p{0.25\textwidth}p{0.25\textwidth}p{0.25\textwidth}p{0.25\textwidth}p{0.25\textwidth}}
  \includegraphics[width=0.25\textwidth]{gt200-die.jpg}
  &
  \includegraphics[width=0.25\textwidth]{fermi-die-shot.jpeg}
  &
  \centering
  \includegraphics[width=3.5cm,angle=90]{ivy-bridge-die-shot.jpeg}
  &
  \includegraphics[width=0.25\textwidth]{tahiti-die-shot.jpeg}
  &
  \includegraphics[width=0.25\textwidth]{gk110-die-shot.jpeg}
  \\
  \centering Nv~GT200\par(2008)
  &
  \centering Nv~Fermi\par(2010)
  &
  \centering Intel IVB\par(2012)
  &
  \centering AMD Tahiti \par(2012)
  &
  \centering Nv GK110\par(2012?)
  \end{tabular}
\end{frame}
% }}}
% -----------------------------------------------------------------------------
\section{OpenCL: Overview}
% -----------------------------------------------------------------------------
% {{{
\begin{frame}{What is OpenCL?}
  \begin{columns}
    \column{0.7\textwidth}

      OpenCL (Open Computing Language) is an open, royalty-free
      standard for general purpose parallel programming across CPUs,
      GPUs and other processors.
      \hfill{\footnotesize[OpenCL 1.1 spec]}
      \bigskip


      \begin{itemize}
        \item Device-neutral (Nv GPU, AMD GPU, Intel/AMD CPU)
        \item Vendor-neutral
        \item Comes with `JIT' compilation
      \end{itemize}
      Defines:
      \begin{itemize}
        \item Host-side programming interface (library)
        \item Device-side programming language (!)
      \end{itemize}

    \column{0.3\textwidth}
      \includegraphics[width=\textwidth] {opencl-logo.png}

  \end{columns}
\end{frame}

\newcommand{\khronoscredit}{
  \begin{tikzpicture}[overlay]
    \node [xshift=1cm,yshift=0.5cm]
      at (current page.south west)
      [font=\scriptsize,fill=gray!30,anchor=south west,opacity=0.5]
      {Credit: Khronos Group};
  \end{tikzpicture}
}
\def\khronosslide#1#2
{
  \begin{frame}{#1}
    \hspace*{-0.75cm}\includegraphics[viewport=2cm 0cm 31cm 14.5cm,clip=true,width=1.15\textwidth,page=#2]{opencl-overview.pdf}
    \khronoscredit
  \end{frame}
}

\input{cl-vocabulary}

%\khronosslide{OpenCL: Execution Model}{11}

{
\def\drawgroup#1{
  \foreach \i in {0,1,...,23}
    \foreach \j in {0,1,...,16}
    {
      \pgfmathtruncatemacro{\grp}{(\i+24*\j)/16}
      \ifthenelse{\equal{\grp}{#1}}
        {\def\grpcolor{gray!60}}
        {\def\grpcolor{gray!30}}
      \draw [line width=0.5pt,fill=\grpcolor] (\i,\j) rectangle +(1,1) ;
    }
}

\input{cl-prog-model-hardware}

\begin{frame}{Dive into OpenCL: Preparation}
  \begin{center}
  \Huge Demo time
  \end{center}
\end{frame}

% }}}
% -----------------------------------------------------------------------------
\section{OpenCL: Between host and device}
% -----------------------------------------------------------------------------
\input{cl-command-queues}
% -----------------------------------------------------------------------------
\section{OpenCL: Device Language}
% -----------------------------------------------------------------------------
% {{{
\begin{frame}{OpenCL Device Language}
  \begin{columns}
    \column{0.7\textwidth}
      OpenCL device language is C99, with these differences:

      \medskip
      \plusball Index getters

      \plusball Memory space qualifiers

      \plusball Vector data types 

      \plusball Many generic (`overloaded') math functions

      \plusball Synchronization

      \minusball Recursion

      \minusball Fine-grained \texttt{malloc()}

      \minusball Function pointers
    \column{0.3\textwidth}
      \includegraphics[width=\textwidth]{opencl-logo.png}
  \end{columns}
\end{frame}

%\input{cuda-cl-dictionary}

\begin{frame}{Address Space Qualifiers}

  \begin{center}
  \begin{tabular}{p{5em}cccp{2.8cm}}
    \hline
    \textbf{Type} & \textbf{Per} & \textbf{``Speed''} \\
    \hline
    private*) & work item & super-fast\\
    local & group & fast \\
    global & grid & kinda slow \\
    \hline
  \end{tabular}

  \bigskip
  *) default, so optional
  \end{center}
  \uncover<2>{
    \begin{tikzpicture} [overlay]
      \node [
        above left=1cm of current page.south east, draw,drop shadow,fill=white,
        inner sep=5mm,thick, text width=0.6\textwidth]
        {
          Should really discuss ``speed'' in terms of
          latency/bandwidth.

          \bigskip
          \emph{Both} decrease with distance from the point of
          execution.
        } ;
    \end{tikzpicture}
  }
\end{frame}

% }}}
% -----------------------------------------------------------------------------
\section{OpenCL: Synchronization}
% -----------------------------------------------------------------------------
% {{{
\begin{nologo}
\begin{frame}{Concurrency and Synchronization}
  \uncover<+->{
    \begin{beamercolorbox}[sep=3mm]{block body}
      GPUs have layers of concurrency.\\
      \hfill Each layer has its synchronization primitives.
    \end{beamercolorbox}
  }
  \bigskip
  \begin{columns}[c]
    \column{0.6\textwidth}
      \uncover<+->{
        \begin{itemize}
          \item Intra-group:\\ 
            \texttt{barrier(\dots)}, \\
            \texttt{mem\_fence(\dots)}\\
            \texttt{\dots} =
            \texttt{CLK\_\{LOCAL,GLOBAL\}\_MEM\_FENCE}
          \item Inter-group:\\ Kernel launch
          \item CPU-GPU:\\ Command queues, Events
        \end{itemize}
      }
    \column{0.35\textwidth}
      \includegraphics[width=\textwidth]{onion.jpeg}
  \end{columns}

\end{frame}
\end{nologo}
\addimgcredit{Onions: flickr.com/darwinbell \cc}

\input{barrier}
\input{memory-fence}

% -----------------------------------------------------------------------------
\begin{frame}{Synchronization between Groups}
  \begin{block}<+->{Golden Rule:}
    Results of the algorithm must be independent of the order in which
    work groups are executed.
  \end{block}

  \uncover<+->{
  \textbf{Consequences:}
  \begin{itemize}
    \item Work groups may read the same information from global memory.
    \item But: Two work groups may not validly write different things to 
      the same global memory.
    \item Kernel launch serves as
      \begin{itemize}
        \item Global barrier
        \item Global memory fence
      \end{itemize}
  \end{itemize}
  }
\end{frame}
% -----------------------------------------------------------------------------
\input{cl-atomic}
% }}}
\questionframe{}
\imagecreditslide

\end{document}
% vim: foldmethod=marker
