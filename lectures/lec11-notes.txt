-------------------------------------------------------------------------------
Diff
-------------------------------------------------------------------------------
In pymbolic tree:

- [PREP] git checkout 4f5490
- [PREP] git checkout -f

- Have a software tree, don't quite know differences to known state
- unset LANG

- diff pymbolic-nogit ~/src/pymbolic
- diff -r pymbolic-nogit ~/src/pymbolic
- diff -r pymbolic-nogit ~/src/pymbolic > diff.txt
- diff -rN pymbolic-nogit ~/src/pymbolic > diff.txt
- diff -r pymbolic-nogit ~/src/pymbolic > diff.txt
- BAD, unreadable format
- diff -ur pymbolic-nogit ~/src/pymbolic > diff.txt

Wouldn't it be handy if I could apply these changes?
-------------------------------------------------------------------------------
Patch
-------------------------------------------------------------------------------
- in pymbolic:
- patch < ../diff.txt
- patch -p1 < ../diff.txt
- git diff

- git config --global color.ui auto
-------------------------------------------------------------------------------
git add -i
-------------------------------------------------------------------------------
- Add some changes, not others

- Add a file from the command line
- Unstage it

- Then git commit

- Why all of that?
  -> So that commits, as much as possible, isolate the smallest possible
     unit of change. Why that? DEBUGGABILITY. When would you search for bugs
     at a commit scale? We'll say more about that shortly.
-------------------------------------------------------------------------------
git stash
-------------------------------------------------------------------------------
Undo a commit:
- git reset
- Comment on 'git reset --hard'
- DANGEROUS

- Show status

- git stash
- git stash apply
- git stash drop
- git stash pop
- git stash list
-------------------------------------------------------------------------------
Git bisect
-------------------------------------------------------------------------------
- descibe situation:
  -> have odd behavior
  -> no idea what's causing it
  -> known good at some earlier point
  -> what the hell broke that?
- python code.py
- show rev tree

- can do git checkout this/that

- git bisect start master 0538dd1
- bad/good/bad/good
- converges surprisingly quickly!
- git bisect reset

- git reflog
-------------------------------------------------------------------------------
GPU Branching Demo
-------------------------------------------------------------------------------
BOX
- show code
- run with 32
- run with 16 (just comment out cases)
- comment on how implemented
- run with 8
- ...
- run with 1
-------------------------------------------------------------------------------
GPU latency demo
-------------------------------------------------------------------------------
BOX:
- show code
- shrink work group size
- EXPLANATION: less latency hiding
- Use 2x ILP
  - halve size
  - halve chunksize
  - add extra fetch/store
- Use 4x ILP
-------------------------------------------------------------------------------
Arch understanding demo
-------------------------------------------------------------------------------
- What the hell is a warp?
- Why is the size of the register file given in kiB?

- mem bw
  bus bits * bus clock /1e3 / 8

-  flops per core, per clock
  fpus * 2

- flop rate [gflops]
  cores * core clock * fpus * 2 * 1e6 / 1e9

- how many scheduling slots per core?
  warp size * (# warps/core)

- how many scheduling slots total?
  * cores
  -> and that's just what the hardware does!

- how much register file per work item?
  -> "I'm going to make a mistake."
  reg file * 1024 / # fpus

  correct:
  reg file * 1024 / # work items

- smem bw / WHAT?
  -> FLOP!

  lmem bw / (#fpus * 2)

- gmem bw / flop?

  (gmem bw *1e9) / (#cores) / (core clock *1e6) / (#fpus * 2)
-------------------------------------------------------------------------------
Occupancy calculator demo
-------------------------------------------------------------------------------
Use gnumeric
- grow work group size up to 256
- observe: occupancy increases
- then increase lmem to 16384
- observe: occupancy drops

- Is occupancy absolutely necessary?
  (No. ILP can be just as good. But you pay with space in the reg.file.)
-------------------------------------------------------------------------------
Gmem access patterns demo
-------------------------------------------------------------------------------
- +i alignment on 295 -- 0 1 2 3 16
- *i strides on 295 -- 0 1 2 4 8 16 32
- +i alignment on 590 -- 0 1 2 3 16
- *i strides on 590 -- 0 1 2 4 8 16 32
-------------------------------------------------------------------------------
Lmem access patterns demo
-------------------------------------------------------------------------------
- +i alignment on 590 -- 0 1 2 3 16
- *i strides on 590 -- 0 1 2 4 8 16 32
-------------------------------------------------------------------------------
Transpose lmem access pattern demo
-------------------------------------------------------------------------------
- show code
- try 16, 17 for second array dimension
-------------------------------------------------------------------------------
Transfer demo
-------------------------------------------------------------------------------
- run with missing finish
- ./transpose-soln 8192 10
- show measurement

- show alloc host ptr/map code
- ./transpose-soln 8192 10
- show measurement

- add finish
- show measurement
-> higher BW + overlap! GOOD
-------------------------------------------------------------------------------
GPU prof demo
-------------------------------------------------------------------------------
nvprof --query-events
COMPUTE_PROFILE=1 COMPUTE_PROFILE_CONFIG=...
-------------------------------------------------------------------------------
a glimpse at MPI performance:
-------------------------------------------------------------------------------
- two key figures? latency/bw

BANDWIDTH:
- bandwidth? walk through benchmark, noting benchmarking tricks:
  "loop": run how often
  "skip": skip the warm-up
  "window-size": keep how many non-blocking requests in flight

- run just on box
  as good as 'memcpy'
  very near memory bandwidth! How many extra buffer copies can there be?
  -> point of all this buffer nonsense

  Implementation matters:
  Previous example uses shared memory between processes
  mpiexec --mca btl self,tcp -n 2
  You see the extra buffer copies!

  Now -H box,slate
  -> Networks slow
  -> cardiac,bowery use faster interconnect, I'd encourage you to try this code
     there and compare with our results

BI-BANDWIDTH:
  quick walkthrough
  full-duplex or aggregate bandwidth?

LATENCY:
  quick walkthrough
  on-host
  on-host tcp
  off-host

